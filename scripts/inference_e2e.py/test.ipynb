{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------Loading data\n",
      "Precomputing the SDF grid and gradients took: 0.273 sec\n",
      "TrajectoryDataset\n",
      "n_trajs: 10000\n",
      "trajectory_dim: (64, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_robotics.torch_utils.seed import fix_random_seed\n",
    "from torch_robotics.torch_utils.torch_utils import get_torch_device\n",
    "from mmd.trainer import get_dataset\n",
    "from mmd.utils.loading import load_params_from_yaml\n",
    "\n",
    "\n",
    "seed = 18 #params.seed\n",
    "fix_random_seed(seed)\n",
    "\n",
    "TRAINED_MODELS_DIR = '../../data_trained_models/'\n",
    "trained_models_dir = TRAINED_MODELS_DIR\n",
    "model_id = 'EnvEmptyNoWait2D-RobotPlanarDisk'\n",
    "model_dir = os.path.join(trained_models_dir, model_id)\n",
    "results_dir = os.path.join(model_dir, 'results_inference', str(seed))\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "args = load_params_from_yaml(os.path.join(model_dir, \"args.yaml\"))\n",
    "\n",
    "device='cuda' #params.device\n",
    "device = get_torch_device(device)\n",
    "tensor_args = {'device': device, 'dtype': torch.float32}\n",
    "\n",
    "train_subset, train_dataloader, val_subset, val_dataloader = get_dataset(\n",
    "    dataset_class='TrajectoryDataset',\n",
    "    use_extra_objects=True,\n",
    "    obstacle_cutoff_margin=0.05,\n",
    "    **args,\n",
    "    tensor_args=tensor_args\n",
    ")\n",
    "dataset = train_subset.dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything befroe go into main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local-scratch/localhome/lya108/mmd/mmd/trainer/trainer.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts: [tensor([0.8000, 0.0000], device='cuda:0'), tensor([-0.4000,  0.6928], device='cuda:0'), tensor([-0.4000, -0.6928], device='cuda:0')]\n",
      "Goals: [tensor([-8.0000e-01,  9.7972e-17], device='cuda:0'), tensor([ 0.4000, -0.6928], device='cuda:0'), tensor([0.4000, 0.6928], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from einops._torch_specific import allow_ops_in_compiled_graph  # requires einops>=0.6.1\n",
    "from typing import Tuple, List\n",
    "\n",
    "from torch_robotics.robots import *\n",
    "from torch_robotics.torch_utils.torch_utils import get_torch_device\n",
    "# from mmd.planners.multi_agent import CBS, PrioritizedPlanning\n",
    "from mmd.planners.multi_agent import End2EndPlanning\n",
    "from mmd.planners.single_agent import MPD, MPDEnd2End, MPDEnsemble\n",
    "from mmd.common.constraints import MultiPointConstraint\n",
    "from mmd.common.conflicts import PointConflict\n",
    "from mmd.common.trajectory_utils import densify_trajs\n",
    "from mmd.common import get_start_goal_pos_circle\n",
    "from mmd.common.pretty_print import *\n",
    "from mmd.config.mmd_params import MMDParams as params\n",
    "from mmd.common.experiments import MultiAgentPlanningSingleTrialConfig, MultiAgentPlanningSingleTrialResult, \\\n",
    "    get_result_dir_from_trial_config, TrialSuccessStatus\n",
    "\n",
    "allow_ops_in_compiled_graph()\n",
    "TRAINED_MODELS_DIR = '../../data_trained_models/'\n",
    "device = 'cuda'\n",
    "device = get_torch_device(device)\n",
    "tensor_args = {'device': device, 'dtype': torch.float32}\n",
    "\n",
    "test_config_single_tile = MultiAgentPlanningSingleTrialConfig()\n",
    "test_config_single_tile.num_agents = 3\n",
    "test_config_single_tile.instance_name = \"test\"\n",
    "# test_config_single_tile.multi_agent_planner_class = \"XECBS\" \n",
    "test_config_single_tile.single_agent_planner_class = \"MPDe2e\" # Or \"MPDEnsemble\"\n",
    "test_config_single_tile.stagger_start_time_dt = 0\n",
    "test_config_single_tile.runtime_limit = 60 * 3  # 3 minutes.\n",
    "test_config_single_tile.time_str = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "test_config_single_tile.render_animation = True\n",
    "\n",
    "example_type = \"single_tile\"\n",
    "test_config_single_tile.global_model_ids = [['EnvEmptyNoWait2D-RobotPlanarDisk']]\n",
    "# test_config_single_tile.global_model_ids = [['EnvConveyor2D-RobotPlanarDisk']]\n",
    "# test_config_single_tile.global_model_ids = [['EnvHighways2D-RobotPlanarDisk']]\n",
    "# test_config_single_tile.global_model_ids = [['EnvDropRegion2D-RobotPlanarDisk']]\n",
    "\n",
    "# Choose starts and goals.\n",
    "test_config_single_tile.agent_skeleton_l = [[[0, 0]]] * test_config_single_tile.num_agents\n",
    "torch.random.manual_seed(10)\n",
    "# start & goal are uniformly distributed on a circle with radiu 0.8\n",
    "test_config_single_tile.start_state_pos_l, test_config_single_tile.goal_state_pos_l = \\\n",
    "get_start_goal_pos_circle(test_config_single_tile.num_agents, 0.8)\n",
    "print(\"Starts:\", test_config_single_tile.start_state_pos_l)\n",
    "print(\"Goals:\", test_config_single_tile.goal_state_pos_l)\n",
    "# test_config_single_tile.n_diffusion_steps = 50\n",
    "\n",
    "#run_multi_agent_trial(test_config_single_tile)\n",
    "#print(GREEN, 'OK.', RESET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main, before planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time_l:[0, 0, 0]\n",
      "debug: global_model_ids: [['EnvEmptyNoWait2D-RobotPlanarDisk']]\n",
      "debug: global model tansforms:[[tensor([0., 0.], device='cuda:0')]]\n",
      "####################################\n",
      "Initializing Planner with Model -- EnvEmptyNoWait2D-RobotPlanarDisk\n",
      "Algorithm -- mmd\n",
      "\n",
      "---------------Loading data\n",
      "Precomputing the SDF grid and gradients took: 0.345 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local-scratch/localhome/lya108/mmd/mmd/datasets/trajectories.py:91: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  trajs_free_tmp = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrajectoryDataset\n",
      "n_trajs: 10000\n",
      "trajectory_dim: (64, 4)\n",
      "\n",
      "[ models/temporal ] Channel dimensions: [(4, 32), (32, 64), (64, 128)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local-scratch/localhome/lya108/mmd/mmd/planners/single_agent/mpd_inner.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(model_dir, 'checkpoints', 'ema_model_current_state_dict.pth' if args[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_state_pos: tensor([0.5000, 0.9000], device='cuda:0')\n",
      "goal_state_pos: tensor([-0.5000,  0.9000], device='cuda:0')\n",
      "start_state_pos: tensor([0.5000, 0.9000], device='cuda:0')\n",
      "goal_state_pos: tensor([-0.5000,  0.9000], device='cuda:0')\n",
      "debug: get hard_conds via dataset.get_hard_conditions: {0: tensor([5.1285e-01, 9.2320e-01, 4.4692e-04, 5.0635e-03], device='cuda:0'), 63: tensor([-5.1295e-01,  9.2320e-01,  4.4692e-04,  5.0635e-03], device='cuda:0')}\n",
      "debug: prepare to constract cost_collision_list\n",
      "debug: cost_composite list got\n",
      "debug: guide is formulated\n"
     ]
    }
   ],
   "source": [
    "test_config = test_config_single_tile\n",
    "start_time_l = [i * test_config.stagger_start_time_dt for i in range(test_config.num_agents)]\n",
    "print(f'start_time_l:{start_time_l}')\n",
    "\n",
    "# ============================\n",
    "# Arguments for the single diffusion planner.\n",
    "# diffusion model & single agent planner\n",
    "# ============================\n",
    "diffusion_planner_model_args = {\n",
    "    # config for diffusion model - no change\n",
    "    'planner_alg': 'mmd',\n",
    "    'use_guide_on_extra_objects_only': params.use_guide_on_extra_objects_only,  #False\n",
    "    'n_samples': params.n_samples,  # how many trajs to be generated by one diffusion model (64)\n",
    "    'n_local_inference_noising_steps': params.n_local_inference_noising_steps,  # 3\n",
    "    'n_local_inference_denoising_steps': params.n_local_inference_denoising_steps,\n",
    "    'start_guide_steps_fraction': params.start_guide_steps_fraction,\n",
    "    'n_guide_steps': params.n_guide_steps,\n",
    "    'n_diffusion_steps_without_noise': params.n_diffusion_steps_without_noise,\n",
    "    # config for low-level planner\n",
    "    'weight_grad_cost_collision': params.weight_grad_cost_collision,\n",
    "    'weight_grad_cost_smoothness': params.weight_grad_cost_smoothness,\n",
    "    'weight_grad_cost_constraints': params.weight_grad_cost_constraints,\n",
    "    'weight_grad_cost_soft_constraints': params.weight_grad_cost_soft_constraints,\n",
    "    'factor_num_interpolated_points_for_collision': params.factor_num_interpolated_points_for_collision,\n",
    "    'trajectory_duration': params.trajectory_duration,\n",
    "    'device': params.device,\n",
    "    'debug': params.debug,\n",
    "    'seed': params.seed,\n",
    "    'results_dir': params.results_dir,\n",
    "    'trained_models_dir': TRAINED_MODELS_DIR,\n",
    "}\n",
    "end_to_end_planner_model_args = {\n",
    "    'start_time_l': start_time_l,\n",
    "    'runtime_limit': test_config.runtime_limit,\n",
    "    # 'n_diffusion_steps': test_config.n_diffusion_steps,\n",
    "    'conflict_type_to_constraint_types': {PointConflict: {MultiPointConstraint}},\n",
    "    'device': params.device,\n",
    "    # device, seed, debug需要挪出来吗？\n",
    "}\n",
    "\n",
    "# ============================\n",
    "# Create a results directory.\n",
    "# ============================\n",
    "results_dir = get_result_dir_from_trial_config(test_config, test_config.time_str, test_config.trial_number)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "num_agents = test_config.num_agents\n",
    "\n",
    "# ============================\n",
    "# Get planning problem.\n",
    "# ============================\n",
    "# If want to get random starts and goals, then must do that after creating the reference task and robot.\n",
    "start_l = test_config.start_state_pos_l\n",
    "goal_l = test_config.goal_state_pos_l\n",
    "global_model_ids = test_config.global_model_ids\n",
    "agent_skeleton_l = test_config.agent_skeleton_l\n",
    "print(f'debug: global_model_ids: {global_model_ids}')\n",
    "\n",
    "# ============================\n",
    "# Transforms and model tiles setup.\n",
    "# ============================\n",
    "# Create a reference planner from which we'll use the task and robot as the reference on in CBS.\n",
    "# Those are used for collision checking and visualization. This has a skeleton of all tiles.\n",
    "reference_agent_skeleton = [[r, c] for r in range(len(global_model_ids))\n",
    "                            for c in range(len(global_model_ids[0]))]\n",
    "\n",
    "# ============================\n",
    "# Transforms from tiles to global frame.\n",
    "# ============================\n",
    "tile_width = 2.0\n",
    "tile_height = 2.0\n",
    "global_model_transforms = [[torch.tensor([x * tile_width, -y * tile_height], **tensor_args)\n",
    "                            for x in range(len(global_model_ids[0]))] for y in range(len(global_model_ids))]    \n",
    "print(f'debug: global model tansforms:{global_model_transforms}')\n",
    "\n",
    "# ============================\n",
    "# Parse the single agent planner class name.\n",
    "# emmm in this case maybe i should start by parser the model?\n",
    "# what exactly was done in the low-level planner\n",
    "# ============================    \n",
    "if test_config.single_agent_planner_class == \"MPDe2e\":\n",
    "    planner_class = MPDEnd2End\n",
    "elif test_config.single_agent_planner_class == \"MPD\":\n",
    "    planner_class = MPD\n",
    "elif test_config.single_agent_planner_class == \"MPDEnsemble\":\n",
    "    planner_class = MPDEnsemble\n",
    "else:\n",
    "    raise ValueError(f'Unknown single agent planner class: {test_config.single_agent_planner_class}')\n",
    "\n",
    "# ============================\n",
    "# Create reference agent planner.\n",
    "# ============================\n",
    "# And for the reference skeleton.\n",
    "reference_task = None\n",
    "reference_robot = None\n",
    "reference_agent_transforms = {}\n",
    "reference_agent_model_ids = {}\n",
    "\n",
    "for skeleton_step in range(len(reference_agent_skeleton)):\n",
    "    skeleton_model_coord = reference_agent_skeleton[skeleton_step]\n",
    "    reference_agent_transforms[skeleton_step] = global_model_transforms[skeleton_model_coord[0]][\n",
    "        skeleton_model_coord[1]]\n",
    "    reference_agent_model_ids[skeleton_step] = global_model_ids[skeleton_model_coord[0]][\n",
    "        skeleton_model_coord[1]]\n",
    "reference_agent_model_ids = [reference_agent_model_ids[i] for i in range(len(reference_agent_model_ids))]\n",
    "# Create the reference low level planner\n",
    "diffusion_planner_model_args['start_state_pos'] = torch.tensor([0.5, 0.9], **tensor_args)  # This does not matter.\n",
    "diffusion_planner_model_args['goal_state_pos'] = torch.tensor([-0.5, 0.9], **tensor_args)  # This does not matter.\n",
    "diffusion_planner_model_args['model_ids'] = reference_agent_model_ids  # This matters.\n",
    "diffusion_planner_model_args['transforms'] = reference_agent_transforms  # This matters.\n",
    "\n",
    "if test_config.single_agent_planner_class in [\"MPD\", \"MPDe2e\"]:\n",
    "    diffusion_planner_model_args['model_id'] = reference_agent_model_ids[0]\n",
    "\n",
    "reference_single_agent_planner = planner_class(**diffusion_planner_model_args)\n",
    "reference_task = reference_single_agent_planner.task\n",
    "reference_robot = reference_single_agent_planner.robot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "Initializing Planner with Model -- EnvEmptyNoWait2D-RobotPlanarDisk\n",
      "Algorithm -- mmd\n",
      "\n",
      "---------------Loading data\n",
      "Precomputing the SDF grid and gradients took: 0.270 sec\n",
      "TrajectoryDataset\n",
      "n_trajs: 10000\n",
      "trajectory_dim: (64, 4)\n",
      "\n",
      "[ models/temporal ] Channel dimensions: [(4, 32), (32, 64), (64, 128)]\n",
      "start_state_pos: tensor([0.8000, 0.0000], device='cuda:0')\n",
      "goal_state_pos: tensor([-8.0000e-01,  9.7972e-17], device='cuda:0')\n",
      "start_state_pos: tensor([0.8000, 0.0000], device='cuda:0')\n",
      "goal_state_pos: tensor([-8.0000e-01,  9.7972e-17], device='cuda:0')\n",
      "debug: get hard_conds via dataset.get_hard_conditions: {0: tensor([8.2059e-01, 5.5552e-05, 4.4692e-04, 5.0635e-03], device='cuda:0'), 63: tensor([-8.2068e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03], device='cuda:0')}\n",
      "debug: prepare to constract cost_collision_list\n",
      "debug: cost_composite list got\n",
      "debug: guide is formulated\n",
      "####################################\n",
      "Initializing Planner with Model -- EnvEmptyNoWait2D-RobotPlanarDisk\n",
      "Algorithm -- mmd\n",
      "\n",
      "---------------Loading data\n",
      "Precomputing the SDF grid and gradients took: 0.270 sec\n",
      "TrajectoryDataset\n",
      "n_trajs: 10000\n",
      "trajectory_dim: (64, 4)\n",
      "\n",
      "[ models/temporal ] Channel dimensions: [(4, 32), (32, 64), (64, 128)]\n",
      "start_state_pos: tensor([-0.4000,  0.6928], device='cuda:0')\n",
      "goal_state_pos: tensor([ 0.4000, -0.6928], device='cuda:0')\n",
      "start_state_pos: tensor([-0.4000,  0.6928], device='cuda:0')\n",
      "goal_state_pos: tensor([ 0.4000, -0.6928], device='cuda:0')\n",
      "debug: get hard_conds via dataset.get_hard_conditions: {0: tensor([-4.1037e-01,  7.1069e-01,  4.4692e-04,  5.0635e-03], device='cuda:0'), 63: tensor([ 4.1027e-01, -7.1058e-01,  4.4692e-04,  5.0635e-03], device='cuda:0')}\n",
      "debug: prepare to constract cost_collision_list\n",
      "debug: cost_composite list got\n",
      "debug: guide is formulated\n",
      "####################################\n",
      "Initializing Planner with Model -- EnvEmptyNoWait2D-RobotPlanarDisk\n",
      "Algorithm -- mmd\n",
      "\n",
      "---------------Loading data\n",
      "Precomputing the SDF grid and gradients took: 0.273 sec\n",
      "TrajectoryDataset\n",
      "n_trajs: 10000\n",
      "trajectory_dim: (64, 4)\n",
      "\n",
      "[ models/temporal ] Channel dimensions: [(4, 32), (32, 64), (64, 128)]\n",
      "start_state_pos: tensor([-0.4000, -0.6928], device='cuda:0')\n",
      "goal_state_pos: tensor([0.4000, 0.6928], device='cuda:0')\n",
      "start_state_pos: tensor([-0.4000, -0.6928], device='cuda:0')\n",
      "goal_state_pos: tensor([0.4000, 0.6928], device='cuda:0')\n",
      "debug: get hard_conds via dataset.get_hard_conditions: {0: tensor([-4.1037e-01, -7.1058e-01,  4.4692e-04,  5.0635e-03], device='cuda:0'), 63: tensor([4.1027e-01, 7.1069e-01, 4.4692e-04, 5.0635e-03], device='cuda:0')}\n",
      "debug: prepare to constract cost_collision_list\n",
      "debug: cost_composite list got\n",
      "debug: guide is formulated\n",
      "Planners creation time: 5.528354644775391\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "debug: [0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Run trial.\n",
    "# ============================\n",
    "exp_name = f'mmd_single_trial'\n",
    "\n",
    "# Transform starts and goals to the global frame. Right now they are in the local tile frames.\n",
    "start_l = [start_l[i] + global_model_transforms[agent_skeleton_l[i][0][0]][agent_skeleton_l[i][0][1]]\n",
    "            for i in range(num_agents)]\n",
    "goal_l = [goal_l[i] + global_model_transforms[agent_skeleton_l[i][-1][0]][agent_skeleton_l[i][-1][1]]\n",
    "            for i in range(num_agents)]\n",
    "\n",
    "# ============================\n",
    "# Create global transforms for each agent's skeleton.\n",
    "# ============================\n",
    "# Each agent has a dict entry. Each entry is a dict with the skeleton steps (0, 1, 2, ...), mapping to the\n",
    "# model transform.\n",
    "agent_model_transforms_l = []\n",
    "agent_model_ids_l = []\n",
    "for agent_id in range(num_agents):\n",
    "    agent_model_transforms = {}\n",
    "    agent_model_ids = {}\n",
    "    for skeleton_step in range(len(agent_skeleton_l[agent_id])):\n",
    "        skeleton_model_coord = agent_skeleton_l[agent_id][skeleton_step]\n",
    "        agent_model_transforms[skeleton_step] = global_model_transforms[skeleton_model_coord[0]][\n",
    "            skeleton_model_coord[1]]\n",
    "        agent_model_ids[skeleton_step] = global_model_ids[skeleton_model_coord[0]][skeleton_model_coord[1]]\n",
    "    agent_model_transforms_l.append(agent_model_transforms)\n",
    "    agent_model_ids_l.append(agent_model_ids)\n",
    "# Change the dict of the model ids to a list sorted by the skeleton steps.\n",
    "agent_model_ids_l = [[agent_model_ids_l[i][j] for j in range(len(agent_model_ids_l[i]))] for i in\n",
    "                        range(num_agents)]\n",
    "# ============================\n",
    "# Create the single agent planners.\n",
    "# ============================\n",
    "planners_creation_start_time = time.time()\n",
    "single_agent_planner_l = []\n",
    "for i in range(num_agents):\n",
    "    single_agent_planner_model_args_i = diffusion_planner_model_args.copy()\n",
    "    single_agent_planner_model_args_i[\"start_state_pos\"] = start_l[i]\n",
    "    single_agent_planner_model_args_i['goal_state_pos'] = goal_l[i]\n",
    "    single_agent_planner_model_args_i['model_ids'] = agent_model_ids_l[i]\n",
    "    single_agent_planner_model_args_i[\"transforms\"] = agent_model_transforms_l[i]\n",
    "    if test_config.single_agent_planner_class in [\"MPD\", \"MPDe2e\"]:\n",
    "        single_agent_planner_model_args_i[\"model_id\"] = agent_model_ids_l[i][0]\n",
    "    single_agent_planner_l.append(planner_class(**single_agent_planner_model_args_i))\n",
    "print('Planners creation time:', time.time() - planners_creation_start_time)\n",
    "print(\"\\n\\n\\n\\n\")\n",
    "\n",
    "# ============================\n",
    "# Create the multi agent planner.\n",
    "# don't really exist, but we use sth like PP\n",
    "# ============================\n",
    "planner = End2EndPlanning(single_agent_planner_l,\n",
    "                            start_l,\n",
    "                            goal_l,\n",
    "                            reference_task=reference_task,\n",
    "                            reference_robot=reference_robot,\n",
    "                            **end_to_end_planner_model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from copy import copy\n",
    "import einops\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from typing import Tuple, List\n",
    "\n",
    "from torch_robotics.trajectory.metrics import compute_smoothness, compute_path_length, compute_variance_waypoints\n",
    "from mp_baselines.planners.costs.cost_functions import CostCollision, CostComposite, CostConstraint\n",
    "from torch_robotics.torch_utils.torch_timer import TimerCUDA\n",
    "from mmd.common.conflicts import Conflict\n",
    "from mmd.common.constraints import MultiPointConstraint\n",
    "from mmd.common.experiments import TrialSuccessStatus\n",
    "from mmd.common.pretty_print import *\n",
    "from mmd.config import MMDParams as params\n",
    "from mmd.common import smooth_trajs, is_multi_agent_start_goal_states_valid, global_pad_paths\n",
    "from mmd.models.diffusion_models.sample_functions import apply_hard_conditioning, ddpm_sample_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m Using random noise in p_sample_loop. Steps (negative attempts to recon. t=0) [25, -1] \u001b[0m\n",
      "\u001b[96m Starting to guide after t < 13 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "num_agent = len(planner.single_agent_planner_l)\n",
    "device = planner.device\n",
    "batch_size = params.n_samples\n",
    "shape = (planner.num_agents, batch_size, params.horizon, planner.single_agent_planner_l[0].state_dim)\n",
    "# added\n",
    "warm_start_path_b = None\n",
    "t_start_guide = planner.single_agent_planner_l[0].t_start_guide\n",
    "n_diffusion_steps = planner.single_agent_planner_l[0].model.n_diffusion_steps\n",
    "return_chain = True\n",
    "n_diffusion_steps_without_noise=planner.single_agent_planner_l[0].n_diffusion_steps_without_noise\n",
    "\n",
    "if warm_start_path_b is not None:\n",
    "    x = warm_start_path_b\n",
    "    print(CYAN, \"Using warm start path in p_sample_loop. Steps (negative attempts to recon. t=0)\", [n_diffusion_steps, -n_diffusion_steps_without_noise], RESET)\n",
    "else:\n",
    "    x = torch.randn(shape, device=device)\n",
    "    print(CYAN, \"Using random noise in p_sample_loop. Steps (negative attempts to recon. t=0)\", [n_diffusion_steps, -n_diffusion_steps_without_noise], RESET)\n",
    "#if 't_start_guide' in sample_kwargs:\n",
    "#    print(CYAN, \"Starting to guide after t <\", sample_kwargs['t_start_guide'], RESET)\n",
    "print(CYAN, \"Starting to guide after t <\", t_start_guide, RESET)\n",
    "# x = apply_hard_conditioning(x, agent.hard_conds)\n",
    "chain = [x] if return_chain else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_step_trajs = x\n",
    "constraint_l = [[] for _ in range(num_agent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timesteps(batch_size, i ,device):\n",
    "    t = torch.full((batch_size,), i, device=device, dtype=torch.long)\n",
    "    return t\n",
    "i = 24\n",
    "t= make_timesteps(batch_size, i, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "agent = planner.single_agent_planner_l[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "hard_conds = copy(agent.hard_conds)\n",
    "context = copy(agent.context)\n",
    "for k, v in hard_conds.items():\n",
    "    new_state = einops.repeat(v, 'd -> b d', b=batch_size)\n",
    "    hard_conds[k] = new_state\n",
    "\n",
    "if context is not None:\n",
    "    for k, v in context.items():\n",
    "        context[k] = einops.repeat(v, 'd -> b d', b=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[j] = apply_hard_conditioning(x[j], hard_conds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_l[j] = planner.create_soft_constraints_from_other_agents_paths(prev_step_trajs, agent_id=j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.update_constraints(constraint_l[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/local-scratch/localhome/lya108/mmd/mmd/models/diffusion_models/sample_functions.py\u001b[0m(58)\u001b[0;36mddpm_sample_fn\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     56 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     57 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 58 \u001b[0;31m    \u001b[0mmodel_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_log_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_mean_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard_conds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhard_conds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     59 \u001b[0;31m    \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     60 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 64, 4])\n",
      "torch.Size([64])\n",
      "> \u001b[0;32m/local-scratch/localhome/lya108/mmd/mmd/models/diffusion_models/diffusion_model_base.py\u001b[0m(153)\u001b[0;36mp_mean_variance\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    151 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    152 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 153 \u001b[0;31m        \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_start_from_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    154 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    155 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_denoised\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "torch.Size([64, 64, 4])\n"
     ]
    }
   ],
   "source": [
    "x[j], _ = ddpm_sample_fn(agent.model, x[j], hard_conds, context, t, guide=agent.guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[j] = apply_hard_conditioning(x[j], hard_conds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.guide.reset_extra_costs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_single = t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if t_single <0:\n",
    "    print('t_single < 0')\n",
    "    t = torch.zeros_like(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(a, t, x_shape):\n",
    "    b, *_ = t.shape\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 8.2059e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03],\n",
       "          [-2.3162e+00,  5.2466e-01,  4.7068e-02,  9.4156e-02],\n",
       "          [-6.5604e-01,  4.4546e-01, -5.2948e-02,  8.5606e-01],\n",
       "          ...,\n",
       "          [ 1.1000e+00,  2.5674e-02,  6.7181e-01,  1.3306e+00],\n",
       "          [ 5.4286e-01,  2.2151e-01, -2.2344e-01,  1.2278e+00],\n",
       "          [-8.2068e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03]],\n",
       "\n",
       "         [[ 8.2059e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03],\n",
       "          [-9.2886e-01, -5.8093e-01, -2.3160e-01,  3.1880e-01],\n",
       "          [-1.2408e-01,  3.6317e-01,  1.4351e+00,  3.5971e-02],\n",
       "          ...,\n",
       "          [ 3.1652e-01,  3.4372e-01,  6.2235e-01,  3.2994e-01],\n",
       "          [ 2.1875e-03, -7.7053e-01,  1.0030e+00, -9.2270e-02],\n",
       "          [-8.2068e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03]],\n",
       "\n",
       "         [[ 8.2059e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03],\n",
       "          [-1.2344e-01, -1.0227e-01, -1.2624e+00, -7.4362e-01],\n",
       "          [ 5.1342e-01, -2.1779e-01, -4.2178e-01, -8.4532e-01],\n",
       "          ...,\n",
       "          [-1.1865e+00,  2.0043e-01, -1.1155e+00,  4.6373e-01],\n",
       "          [-1.9953e+00, -5.9607e-02,  4.2235e-01, -2.4977e-01],\n",
       "          [-8.2068e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 8.2059e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03],\n",
       "          [ 5.8285e-01, -1.5630e+00, -1.3209e+00,  3.9436e-01],\n",
       "          [ 3.7872e-01,  1.3270e+00, -1.6816e+00, -2.5776e+00],\n",
       "          ...,\n",
       "          [-1.8547e-01,  3.0013e-01, -9.2102e-01,  2.0363e+00],\n",
       "          [-3.4720e-01,  3.0482e-01,  1.3455e+00, -6.7409e-01],\n",
       "          [-8.2068e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03]],\n",
       "\n",
       "         [[ 8.2059e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03],\n",
       "          [ 1.6498e-01, -1.3560e-01, -8.0261e-01,  6.0108e-01],\n",
       "          [-1.0572e+00,  8.7810e-01, -1.7419e-01,  9.9078e-01],\n",
       "          ...,\n",
       "          [ 3.1650e-01, -6.5949e-01,  9.0162e-01, -9.2612e-01],\n",
       "          [ 4.8087e-01, -5.3180e-01,  1.2033e-01, -1.1418e+00],\n",
       "          [-8.2068e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03]],\n",
       "\n",
       "         [[ 8.2059e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03],\n",
       "          [ 1.1147e+00,  5.7572e-01, -3.2789e-01,  2.5416e-02],\n",
       "          [-1.6254e+00, -7.8278e-01,  1.3982e+00,  1.5269e+00],\n",
       "          ...,\n",
       "          [-6.4630e-01, -1.5205e-01, -1.6654e+00, -2.0576e-01],\n",
       "          [ 1.9155e+00,  1.6297e-01, -6.6333e-01, -4.7668e-01],\n",
       "          [-8.2068e-01,  5.5552e-05,  4.4692e-04,  5.0635e-03]]],\n",
       "\n",
       "\n",
       "        [[[-1.8336e-01,  1.2030e+00,  1.3920e+00, -4.2420e-01],\n",
       "          [ 8.2442e-01,  1.3620e+00,  5.7868e-01, -2.0474e+00],\n",
       "          [-1.9087e-01, -9.1601e-01,  6.6118e-01, -5.3872e-02],\n",
       "          ...,\n",
       "          [-5.6860e-01,  4.9397e-01,  9.2740e-01, -8.9939e-02],\n",
       "          [-1.7751e+00, -6.7365e-01, -1.3318e-01, -6.7936e-01],\n",
       "          [-2.3228e+00,  2.6550e-01,  1.1250e+00, -6.0095e-01]],\n",
       "\n",
       "         [[ 1.7997e-01, -7.8564e-01, -1.6809e+00, -1.3424e+00],\n",
       "          [-2.3374e+00, -2.7927e-01, -4.2814e-01, -2.0259e+00],\n",
       "          [-4.4800e-01,  1.0924e+00, -9.0697e-01, -7.8214e-02],\n",
       "          ...,\n",
       "          [-1.3981e+00,  8.1695e-01,  2.1292e-01, -2.9040e-02],\n",
       "          [ 3.1579e-01,  1.2267e+00,  7.3936e-01,  1.1102e+00],\n",
       "          [ 1.7206e+00, -2.4580e-01,  2.3771e-01, -1.1684e+00]],\n",
       "\n",
       "         [[-1.0833e+00,  1.5809e-01,  2.0148e-01, -7.2031e-01],\n",
       "          [-2.2386e-01, -3.8346e-01, -1.1026e+00, -3.4169e-01],\n",
       "          [-1.1306e+00,  6.7704e-03, -1.4653e+00, -8.3880e-02],\n",
       "          ...,\n",
       "          [ 3.0683e-01, -9.6063e-01,  1.5105e+00,  2.0968e-01],\n",
       "          [-2.2987e-01,  1.1913e+00,  4.4108e-01, -1.3174e+00],\n",
       "          [ 4.7023e-02, -6.2655e-01, -1.1911e+00,  1.2022e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.1960e-01,  2.2644e+00,  4.0833e-01,  1.0633e+00],\n",
       "          [ 6.4754e-01,  1.5757e+00,  5.6713e-01,  9.2521e-01],\n",
       "          [ 1.1722e+00, -5.9231e-01,  9.2814e-01, -1.6128e+00],\n",
       "          ...,\n",
       "          [-8.4045e-01,  1.6549e+00,  1.4423e+00,  1.4792e-01],\n",
       "          [-3.0973e+00, -7.0320e-01, -1.1750e+00, -2.7167e-01],\n",
       "          [ 3.8409e-01,  3.5706e-01, -1.1506e+00, -1.6238e+00]],\n",
       "\n",
       "         [[ 4.6823e-02,  2.8048e-01, -6.1487e-01, -1.7684e+00],\n",
       "          [-1.0016e-01,  1.0373e+00, -1.3781e+00, -2.5890e-02],\n",
       "          [ 3.8518e-01, -3.7326e-01, -1.3050e-01,  3.3310e-01],\n",
       "          ...,\n",
       "          [ 6.1066e-01, -6.3843e-01,  1.7239e+00,  1.2535e+00],\n",
       "          [-1.8914e-01, -2.4228e-01, -1.7895e+00, -1.0440e+00],\n",
       "          [-5.7445e-01, -1.5473e-01, -6.2797e-01, -7.4619e-01]],\n",
       "\n",
       "         [[ 1.0024e+00, -4.4048e-01,  5.2299e-02, -1.1897e+00],\n",
       "          [ 2.0429e+00,  5.1634e-02, -9.2734e-01,  1.7055e+00],\n",
       "          [ 1.5323e+00,  1.2319e+00, -7.9215e-01, -2.2454e-01],\n",
       "          ...,\n",
       "          [-1.1031e+00,  1.1787e+00,  1.2109e+00,  1.0265e+00],\n",
       "          [ 3.0430e-01,  4.0120e-01,  3.4276e-01,  1.1039e+00],\n",
       "          [-5.3306e-01, -8.5463e-01, -7.3414e-01, -1.2754e+00]]],\n",
       "\n",
       "\n",
       "        [[[-1.0346e+00,  9.1595e-01, -3.5760e-01, -1.0077e+00],\n",
       "          [ 9.0122e-01,  3.4331e-01, -2.7550e+00,  1.3448e-01],\n",
       "          [-5.3579e-02, -4.6882e-01, -1.8055e+00, -3.1295e-02],\n",
       "          ...,\n",
       "          [ 6.5156e-01, -1.4301e-01,  4.3702e-01, -4.2423e-01],\n",
       "          [ 9.5650e-01,  7.9020e-01,  1.0011e+00,  1.3402e-01],\n",
       "          [ 1.3375e+00,  6.2369e-01, -1.5996e-01, -2.9013e-01]],\n",
       "\n",
       "         [[ 9.9080e-01, -6.3138e-01, -7.4918e-01, -2.1990e-01],\n",
       "          [-3.2246e-01,  4.6602e-01,  3.8684e-01,  8.3681e-01],\n",
       "          [-1.7261e-01, -8.0305e-01, -7.6372e-01,  1.5738e+00],\n",
       "          ...,\n",
       "          [-7.5180e-01,  2.4398e+00,  1.2199e+00,  1.5163e+00],\n",
       "          [ 9.7245e-01, -8.5265e-01, -4.4383e-02, -9.6482e-01],\n",
       "          [-1.0900e+00, -7.1368e-01, -1.2973e-01, -7.2418e-01]],\n",
       "\n",
       "         [[ 8.0495e-01, -1.8820e-02, -8.0490e-01,  2.1479e+00],\n",
       "          [-3.7198e-02,  6.9840e-01, -1.6372e+00,  8.6654e-01],\n",
       "          [ 7.5557e-01, -9.7350e-01,  8.7533e-02, -1.5616e-01],\n",
       "          ...,\n",
       "          [ 3.7669e-02, -5.9184e-01,  5.4520e-01, -2.7243e-01],\n",
       "          [-2.1004e+00, -6.8973e-01,  1.8059e+00,  1.5519e+00],\n",
       "          [ 9.2728e-01,  6.3601e-01,  7.3861e-01, -6.0904e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.6127e-01, -7.5045e-03,  6.8058e-01,  5.5009e-01],\n",
       "          [ 1.6938e-01, -8.1825e-01,  8.1066e-01,  1.4140e+00],\n",
       "          [ 2.9769e-01, -8.4720e-01,  7.1785e-02,  1.2015e-01],\n",
       "          ...,\n",
       "          [ 6.1148e-01, -4.4202e-01, -1.7114e+00,  5.8294e-01],\n",
       "          [-2.1333e-01, -1.5581e+00,  5.3642e-02,  1.3752e+00],\n",
       "          [ 1.2408e-01,  1.4513e+00,  9.4411e-01, -1.1937e+00]],\n",
       "\n",
       "         [[ 5.3397e-02,  4.3226e-01,  7.1319e-02, -1.1327e+00],\n",
       "          [ 7.0720e-01, -3.5531e-01,  1.7979e+00,  1.3725e+00],\n",
       "          [ 3.7407e-01,  8.5930e-01, -1.6167e+00,  1.0215e+00],\n",
       "          ...,\n",
       "          [-6.6464e-01, -2.7062e+00,  1.3012e+00, -3.9899e-01],\n",
       "          [ 2.6159e-01,  5.4018e-01, -4.2652e-01, -3.9932e-01],\n",
       "          [-7.3763e-01, -7.8209e-01, -1.1718e-01,  2.8187e-01]],\n",
       "\n",
       "         [[-3.2848e-01,  1.4368e-01, -2.4770e-01,  1.1806e-01],\n",
       "          [-5.6591e-02,  1.5667e-01,  1.2681e+00, -1.2802e-01],\n",
       "          [-8.3083e-02,  1.8329e+00, -7.3673e-01, -2.7975e-01],\n",
       "          ...,\n",
       "          [ 8.9974e-01, -5.5354e-01, -2.9069e-01,  3.4732e-01],\n",
       "          [ 2.0136e+00,  1.6286e-02, -9.1290e-01,  1.6080e-01],\n",
       "          [-5.9689e-01,  5.2080e-01, -3.2613e-02,  1.7300e+00]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = x\n",
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m noise \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmd-dev/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmd-dev/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmd-dev/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:433\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m saved_dynamic_layer_stack_depth \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    429\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mget_dynamic_layer_stack_depth()\n\u001b[1;32m    430\u001b[0m )\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[1;32m    437\u001b[0m         saved_dynamic_layer_stack_depth\n\u001b[1;32m    438\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mmd-dev/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmd-dev/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/local-scratch/localhome/lya108/mmd/mmd/models/diffusion_models/diffusion_model_base.py:310\u001b[0m, in \u001b[0;36mGaussianDiffusionModel.forward\u001b[0;34m(self, cond, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, cond, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconditional_sample(cond, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "noise = agent.model(x_t, t, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]],\n",
       "\n",
       "\n",
       "        [[[4602.6675]]]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract(agent.model.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t - extract(agent.model.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent.model.sqrt_recip_alphas_cumprod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract(agent.sqrt_recip_alphas_cumprod, t, x_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_mean, _, model_log_variance = model.p_mean_variance(x=x, hard_conds=hard_conds, context=context, t=t)\n",
    "x_recon = agent.model.predict_start_from_noise(x, t=t, noise=agent.model.model(x, t, context))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmd-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
