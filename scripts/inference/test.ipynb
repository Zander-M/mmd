{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List, Optional\n",
    "\n",
    "from mp_baselines.planners.chomp import CHOMP\n",
    "from mp_baselines.planners.costs.factors.field_factor import FieldFactor\n",
    "from mp_baselines.planners.costs.factors.gp_factor import GPFactor\n",
    "from mp_baselines.planners.costs.factors.unary_factor import UnaryFactor\n",
    "from torch_robotics.torch_kinematics_tree.geometrics.utils import link_pos_from_link_tensor\n",
    "from torch_robotics.torch_planning_objectives.fields.distance_fields import interpolate_points_v1\n",
    "from torch_robotics.torch_utils.torch_utils import batched_weighted_dot_prod\n",
    "from torch_robotics.trajectory.utils import finite_difference_vector\n",
    "\n",
    "\n",
    "class Cost(ABC):\n",
    "    def __init__(self, robot, n_support_points, tensor_args=None, **kwargs):\n",
    "        self.robot = robot\n",
    "        self.n_dof = robot.q_dim\n",
    "        self.dim = 2 * self.n_dof  # position + velocity\n",
    "        self.n_support_points = n_support_points\n",
    "\n",
    "        self.tensor_args = tensor_args\n",
    "\n",
    "    def set_cost_factors(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, trajs, **kwargs):\n",
    "        return self.eval(trajs, **kwargs)\n",
    "\n",
    "    @abstractmethod\n",
    "    def eval(self, trajs, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_linear_system(self, trajs, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def get_q_pos_vel_and_fk_map(self, trajs, **kwargs):\n",
    "        assert trajs.ndim == 3 or trajs.ndim == 4\n",
    "        N = 1\n",
    "        if trajs.ndim == 4:\n",
    "            N, B, H, D = trajs.shape  # n_goals (or steps), batch of trajectories, length, dim\n",
    "            trajs = einops.rearrange(trajs, 'N B H D -> (N B) H D')\n",
    "        else:\n",
    "            B, H, D = trajs.shape\n",
    "\n",
    "        q_pos = self.robot.get_position(trajs)\n",
    "        q_vel = self.robot.get_velocity(trajs)\n",
    "        H_positions = self.robot.fk_map_collision(\n",
    "            q_pos)  # I, taskspaces, x_dim+1, x_dim+1 (homogeneous transformation matrices)\n",
    "        return trajs, q_pos, q_vel, H_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn((2,3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a[0][1].squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmd-dev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
